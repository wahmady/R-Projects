stem(iridium)
boxplot(rhodium)
boxplot(iridium)
#iridum data contains more outliers.
plot(rhodium) + plot(iridium)
#e. The data is indepndent and there are measurement errors because of the amount of outliers in the data.
#f)
mean(rhodium, trim = .10)
mean(rhodium, trim = .20)
mean(iridium, trim = .10)
mean(iridium, trim = .20)
r_med <- median(rhodium)
i_med <- median(iridium)
rm <- mean(rhodium)
im <- mean(iridium)
rs <- sd(rhodium)
is <- sd(iridium)
#the more you trim the mean the closer it gets to the median.
#g)
CI_1 <- c(rm - 1.65*rs, rm + 1.65*rs)
CI_2 <- c(im - 1.65*is, im + 1.65*is)
#confidence interval for rhodium, and mean and sd
CI_1
rm
rs
#confidence interval for iridium, and mean and sd
CI_2
rm
rs
#h: Find CI for median
CI_3 <- c(r_med - 1.65*rs, r_med+ 1.65*rs)
CI_4 <- c(i_med - 1.65*is, i_med + 1.65*is)
#Confidence interval using the median for rhodium
CI_3
#Confidence interval using the median for iridium
CI_4
plot(ex, sd_log(ex))
set.seed(1)
sd(ex)
sd_log <- function(t){
sqrt((exp(t) -2)/100)
}
plot(ex, sd_log(ex))
sim_exp1 <- rexp(100, 1)
ex <- rexp(100,1)
sd(ex)
sd_log <- function(t){
sqrt((exp(t) -2)/100)
}
plot(ex, sd_log(ex))
ls()
library(MASS)
library(caTools)
library(dplyr)
library(rpart)
library(rpart.plot)
library(randomForest)
library(caret)
library(tm.plugin.webmining)
library(qdap)
library(tm)
library(NLP)
library(SnowballC)
data <- read.csv("ggplot2questions2018.csv", stringsAsFactors = FALSE)
data$Sig <- as.factor(as.numeric(data$Score > 0))
corpTitle = Corpus(VectorSource(data$Title))
corpBody = Corpus(VectorSource(data$Body))
len = length(corpBody)
for(i in 1:len){
corpBody[[i]] <- extractHTMLStrip(corpBody[[i]])
}
corpTitle = tm_map(corpTitle, removeWords, c(stopwords("english")))
corpBody = tm_map(corpBody, removeWords, c(stopwords("english")))
corpTitle = tm_map(corpTitle, stemDocument)
corpBody = tm_map(corpBody, stemDocument)
corpTitle = tm_map(corpTitle, removePunctuation)
corpBody = tm_map(corpBody, removePunctuation)
corpTitle = tm_map(corpTitle, tolower)
corpBody = tm_map(corpBody, tolower)
freqTitle = DocumentTermMatrix(corpTitle)
freqBody = DocumentTermMatrix(corpBody)
findFreqTerms(freqTitle, lowfreq=50)
findFreqTerms(freqBody, lowfreq=50)
stitle<-removeSparseTerms(freqTitle,0.93)
sbody<-removeSparseTerms(freqBody, 0.77)
#the individual words are the variables, and the predictor is usefulness.
TitleTM <- as.data.frame(as.matrix(stitle))
BodyTM <- as.data.frame(as.matrix(sbody))
colnames(TitleTM) = make.names(colnames(TitleTM))
colnames(BodyTM) = make.names(colnames(BodyTM))
#TitleTM$Useful = dataso$Useful
BodyTM$Sig = data$Sig
# Strip HTMLtags
dataSig <- data[data$Sig==1,]
newCols <- c("Title_ggplot", "Title_ggplot2", "Title_plot", "Title_use", "Title_label", "Title_legend", "Title_line")
colnames(TitleTM) <- newCols
modeldata <- cbind(TitleTM, BodyTM)
modeldata$TitleWords <- sapply(data$Title, function(x) length(unlist(strsplit(as.character(x), "\\W+"))))
modeldata$BodyWords <- sapply(data$Body, function(x) length(unlist(strsplit(as.character(x), "\\W+"))))
set.seed(124)
spl <- sample.split(modeldata$Sig, SplitRatio = 0.7)
traindata = modeldataso %>% filter(spl == TRUE)
traindata = modeldata %>% filter(spl == TRUE)
traindata = modeldata %>% filter(spl == TRUE)
traindata = modeldata %>% filter(spl == TRUE)
modeldata <- subset( modeldata, select = -NA )
summary(modeldata)
library(plyr)
rename(modeldata, c("NA"="na"))
modeldata <- rename(modeldata, c("NA"="na"))
names(modeldata)[names(modeldata)=="NA"] <- "na"
modeldata <- names(modeldata)[names(modeldata)=="NA"] <- "na"
modeldata <- cbind(TitleTM, BodyTM)
modeldata$TitleWords <- sapply(data$Title, function(x) length(unlist(strsplit(as.character(x), "\\W+"))))
modeldata$TitleWords <- sapply(data$Title, function(x) length(unlist(strsplit(as.character(x), "\\W+"))))
modeldata$BodyWords <- sapply(data$Body, function(x) length(unlist(strsplit(as.character(x), "\\W+"))))
summary(modeldata)
set.seed(124)
set.seed(124)
spl <- sample.split(modeldata$Sig, SplitRatio = 0.7)
traindata = modeldata %>% filter(spl == TRUE)
View(modeldata)
names(modeldata)[3] <- "na"
modeldata <- cbind(TitleTM, BodyTM)
modeldata <- cbind(TitleTM, BodyTM)
modeldata$TitleWords <- sapply(data$Title, function(x) length(unlist(strsplit(as.character(x), "\\W+"))))
modeldata$BodyWords <- sapply(data$Body, function(x) length(unlist(strsplit(as.character(x), "\\W+"))))
names(modeldata)[8] <- "na"
set.seed(124)
spl <- sample.split(modeldata$Sig, SplitRatio = 0.7)
traindata = modeldata %>% filter(spl == TRUE)
testdata = modeldata %>% filter(spl == FALSE)
modelRF = randomForest(Sig ~ ., data=traindata)
predictRF = predict(modelRF, data = testdata)
table(datasoTest$Useful, predictRF)
table(dataTest$Sig, predictRF)
table(testdata$Sig, predictRF)
table(testdata$Sig, predictRF)
tableAccuracy <- function(test, pred) {
t = table(test, pred)
a = sum(diag(t))/length(test)
return(a)
}
table(testdata$Sig, predictRF)
tableAccuracy(datasoTest$Useful, predictRF)
tableAccuracy(testdata$Sig, predictRF)
table(testdata$Sig, predictRF)
tableAccuracy <- function(test, pred) {
t = table(test, pred)
a = sum(diag(t))/length(test)
return(a)
}
tableAccuracy(testdata$Sig, predictRF)
summary(modeldata)
library(plyr)
names(modeldata)[8] <- "na"
set.seed(124)
spl <- sample.split(modeldata$Sig, SplitRatio = 0.7)
traindata = modeldata %>% filter(spl == TRUE)
testdata = modeldata %>% filter(spl == FALSE)
modelRF = randomForest(Sig ~ ., data=traindata)
predictRF = predict(modelRF, data = testdata)
table(testdata$Sig, predictRF)
table(testdata$Sig, predictRF)
table(testdata$Sig, predictRF)
tableAccuracy(testdata$Sig, predictRF)
tableAccuracy(testdata, predictRF)
tableAccuracy(testdata, predictRF)
tableAccuracy(testdata, predictRF)
# CART Model
set.seed(1234)
train.cart = train(Useful ~ .,
dataso = datasoTrain,
method = "rpart",
tuneGrid = dataso.frame(cp=seq(0, 0.4, 0.002)),
trControl = trainControl(method="cv", number=10))
set.seed(1234)
train.cart = train(Sig ~ .,
data = traindata,
method = "rpart",
tuneGrid = dataso.frame(cp=seq(0, 0.4, 0.002)),
trControl = trainControl(method="cv", number=10))
set.seed(1234)
train.cart = train(Sig ~ .,
data = traindata,
method = "rpart",
tuneGrid = data.frame(cp=seq(0, 0.4, 0.002)),
trControl = trainControl(method="cv", number=10))
install.packages("e1071")
set.seed(1234)
train.cart = train(Sig ~ .,
data = traindata,
method = "rpart",
tuneGrid = data.frame(cp=seq(0, 0.4, 0.002)),
trControl = trainControl(method="cv", number=10))
train.cart
train.cart$results
mod.cart = train.cart$finalModel
predict.cart = predict(mod.cart, newdataso = datasoTest, type = "class")
table(datasoTest$Useful, predict.cart)
table(testdata$Sig, predict.cart)
TitleTM <- as.data.frame(as.matrix(stitle))
BodyTM <- as.data.frame(as.matrix(sbody))
colnames(TitleTM) = make.names(colnames(TitleTM))
colnames(BodyTM) = make.names(colnames(BodyTM))
#TitleTM$Useful = dataso$Useful
BodyTM$Sig = data$Sig
# Strip HTMLtags
dataSig <- data[data$Sig==1,]
newCols <- c("Title_ggplot", "Title_ggplot2", "Title_plot", "Title_use", "Title_label", "Title_legend", "Title_line")
colnames(TitleTM) <- newCols
modeldata <- cbind(TitleTM, BodyTM)
modeldata$TitleWords <- sapply(data$Title, function(x) length(unlist(strsplit(as.character(x), "\\W+"))))
modeldata$BodyWords <- sapply(data$Body, function(x) length(unlist(strsplit(as.character(x), "\\W+"))))
summary(modeldata)
library(plyr)
names(modeldata)[8] <- "na"
set.seed(124)
spl <- sample.split(modeldata$Sig, SplitRatio = 0.7)
traindata = modeldata %>% filter(spl == TRUE)
testdata = modeldata %>% filter(spl == FALSE)
modelRF = randomForest(Sig ~ ., data=traindata)
predictRF = predict(modelRF, data = testdata)
tableAccuracy <- function(test, pred) {
t = table(test, pred)
a = sum(diag(t))/length(test)
return(a)
}
tableAccuracy(testdata, predictRF)
summary(predictRF)
tableAccuracy(testdata, predictRF)
summary(predict.cart)
summary(predictRF)
summary(predict.cart)
set.seed(1234)
train.cart = train(Sig ~ .,
data = traindata,
method = "rpart",
tuneGrid = data.frame(cp=seq(0, 0.4, 0.002)),
trControl = trainControl(method="cv", number=10))
train.cart
train.cart$results
mod.cart = train.cart$finalModel
predict.cart = predict(mod.cart, newdataso = datasoTest, type = "class") # why no model.matrix?
table(testdata$Sig, predict.cart)
summary(predictRF)
(3026)/(3026+1607)
tableAccuracy(testdata$Sig,predictRF)
summary(testdata$Sig)
predictRF = predict(modelRF, data = testdata)
summary(predictRF)
View(testdata)
predictRF = predict(modelRF, data = testdata)
summary(predictRF)
setwd("C:/Users/wahab/Desktop/IEOR PROJECT")
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(GGally)
library(caTools)
library(ROCR)
library(MASS)
library(caTools)
library(tidyverse)
library(readxl)
library(stringr)
library(softImpute)
library(reshape2)
library(plyr)
library(dplyr)
library(ranger)
library(caret)
OSR2 <- function(predictions, train, test) { SSE <- sum((test - predictions)^2)
SST <- sum((test - mean(train))^2)
r2 <- 1 - SSE/SST
return(r2) }
apple <- read.csv("Apple_price(bro).csv")
summary(apple)
hist(apple$user_rating)
train.ids <- sample(nrow(apple), 0.70*nrow(apple))
train <- apple[train.ids, ]
test_data <- apple[-train.ids, ]
apple$size_bytes
#train regression
traindata_X <- train[c("price", "rating_count_tot", "prime_genre", "size_bytes")]
traindata_Y <- train[c("user_rating")]
testdata_X <- test_data[c("price", "rating_count_tot", "prime_genre", "size_bytes")]
testdata_Y <- test_data[c("user_rating")]
str
linmod <- lm(user_rating ~ prime_genre + price + rating_count_tot + size_bytes + cont_rating, data = train)
summary(linmod)
Lin_Model_Predictions = predict(linmod, newdata = test_data)
summary(Lin_Model_Predictions)
MAE_Lin = mean(abs(Lin_Model_Predictions - test_data$user_rating))
RMSE_Lin = sqrt(mean((Lin_Model_Predictions - test_data$user_rating)^2))
OSR_Lin = OSR2(Lin_Model_Predictions, train$user_rating, test_data$user_rating)
MAE_Lin
RMSE_Lin
OSR_Lin
#Predictions are weak in a regression sense. We can not use a linear model
#apple2 <- read.csv("Apple_price(new).csv")
#summary(apple2)
#train.ids <- sample(nrow(apple2), 0.70*nrow(apple2))
#train2 <- apple2[train.ids, ]
#test_data2 <- apple2[-train.ids, ]
#train regression
#traindata_X2 <- train[c("price", "rating_count_tot", "prime_genre")]
#traindata_Y2 <- train[c("user_rating")]
#testdata_X2 <- test_data2[c("price", "rating_count_tot", "prime_genre")]
#testdata_Y2 <- test_data2[c("user_rating")]
str(train2)
#apple2 <- read.csv("Apple_price(new).csv")
#summary(apple2)
#train.ids <- sample(nrow(apple2), 0.70*nrow(apple2))
#train2 <- apple2[train.ids, ]
#test_data2 <- apple2[-train.ids, ]
#train regression
#traindata_X2 <- train[c("price", "rating_count_tot", "prime_genre")]
#traindata_Y2 <- train[c("user_rating")]
#testdata_X2 <- test_data2[c("price", "rating_count_tot", "prime_genre")]
#testdata_Y2 <- test_data2[c("user_rating")]
#str(train2)
LogRegModel <- glm(user_rating ~ price + rating_count_tot + prime_genre + size_bytes + cont_rating, data = train, family="binomial")
summary(LogRegModel)
logpred <- predict(LogRegModel, newdata=train, type="response")
table(train$user_rating, logpred > 0.5)
# Test Set Prediction
predLogTest <- predict(LogRegModel, newdata=test_data, type="response")
table(test_data$user_rating, predLogTest > 0.5)
#Figure out baseline
#ROC
# ROC Curve
roc_pred <- prediction(predLogTest, test_data$user_rating)
logofperformance <- performance(roc_pred, "tpr", "fpr")
plot(logofperformance, colorize = TRUE)
abline(0, 1)
as.numeric(performance(roc_pred, "auc")@y.values)
#LDA
LdaMod <- lda(user_rating ~ price + rating_count_tot + prime_genre + size_bytes + cont_rating, data = train)
summary(LdaMod)
TestLDApred <- predict(LdaMod, newdata= test_data)
prob_TestLDApred <- TestLDApred$posterior[,2]
roc_lda_pred <- prediction(prob_TestLDApred, test_data$user_rating)
performance_of_lda <- performance(roc_lda_pred, "tpr", "fpr")
plot(performance_of_lda, colorize = TRUE)
abline(0, 1)
as.numeric(performance(roc_lda_pred, "auc")@y.values)
plot(logofperformance, col="violetred3")
plot(performance_of_lda, col="steelblue4", add=TRUE)
abline(0,1)
knitr::opts_chunk$set(echo = TRUE)
ggcoef(
linmod,
vline_color = "red",
vline_linetype =  "solid",
errorbar_color = "blue",
errorbar_height = .25,
exclude_intercept = TRUE
)
#use cart model and random forest
tableAccuracy <- function(test, pred) {
t = table(test, pred)
a = sum(diag(t))/length(test)
return(a)
}
library(caTools) # splits
library(rpart) # CART
library(rpart.plot) # CART plotting
library(caret) # cross validation
train$user_rating
str(train)
train$user_rating <- factor(train$user_rating, levels = c(0, 1), ordered = TRUE)
set.seed(3100)
train.cart = train(user_rating ~ price + rating_count_tot + prime_genre + size_bytes + cont_rating,
data = train,
method = "rpart",
tuneGrid = data.frame(cp = seq(0,0.4,0.002)),
trControl = trainControl(method = "cv", number = 10),
metric = "Accuracy")
train.cart
train.cart$results
ggplot(train.cart$results, aes(x = cp, y = Accuracy)) + geom_point(size = 2) + geom_line() +
ylab("CV Accuracy") + theme_bw() +
theme(axis.title=element_text(size=18), axis.text=element_text(size=18))
mod.cart = train.cart$finalModel
prp(mod.cart)
test_data.mm = as.data.frame((model.matrix(user_rating~.+0,data= test_data)))
predict.cart = predict(mod.cart, newdata = test_data.mm, type = "class")
table(test_data$user_rating, predict.cart)
tableAccuracy(test_data$user_rating, predict.cart)
library(ggplot2)
library(dplyr)
library(GGally)
library(caTools)
library(ROCR)
library(MASS)
library(caTools)
library(tidyverse)
library(readxl)
library(stringr)
library(softImpute)
library(reshape2)
library(plyr)
library(dplyr)
library(ranger)
library(caret)
OSR2 <- function(predictions, train, test) { SSE <- sum((test - predictions)^2)
SST <- sum((test - mean(train))^2)
r2 <- 1 - SSE/SST
return(r2) }
apple <- read.csv("Apple_price(bro).csv")
summary(apple)
hist(apple$user_rating)
train.ids <- sample(nrow(apple), 0.70*nrow(apple))
train <- apple[train.ids, ]
test_data <- apple[-train.ids, ]
apple$size_bytes
#train regression
traindata_X <- train[c("price", "rating_count_tot", "prime_genre", "size_bytes")]
traindata_Y <- train[c("user_rating")]
testdata_X <- test_data[c("price", "rating_count_tot", "prime_genre", "size_bytes")]
testdata_Y <- test_data[c("user_rating")]
linmod <- lm(user_rating ~ prime_genre + price + rating_count_tot + size_bytes + cont_rating, data = train)
summary(linmod)
Lin_Model_Predictions = predict(linmod, newdata = test_data)
summary(Lin_Model_Predictions)
MAE_Lin = mean(abs(Lin_Model_Predictions - test_data$user_rating))
RMSE_Lin = sqrt(mean((Lin_Model_Predictions - test_data$user_rating)^2))
OSR_Lin = OSR2(Lin_Model_Predictions, train$user_rating, test_data$user_rating)
MAE_Lin
RMSE_Lin
OSR_Lin
ggcoef(
linmod,
vline_color = "red",
vline_linetype =  "solid",
errorbar_color = "blue",
errorbar_height = .25,
exclude_intercept = TRUE
)
#Predictions are weak in a regression sense. We can not use a linear model
#apple2 <- read.csv("Apple_price(new).csv")
#summary(apple2)
#train.ids <- sample(nrow(apple2), 0.70*nrow(apple2))
#train2 <- apple2[train.ids, ]
#test_data2 <- apple2[-train.ids, ]
#train regression
#traindata_X2 <- train[c("price", "rating_count_tot", "prime_genre")]
#traindata_Y2 <- train[c("user_rating")]
#testdata_X2 <- test_data2[c("price", "rating_count_tot", "prime_genre")]
#testdata_Y2 <- test_data2[c("user_rating")]
#str(train2)
LogRegModel <- glm(user_rating ~ price + rating_count_tot + prime_genre + size_bytes + cont_rating, data = train, family="binomial")
summary(LogRegModel)
logpred <- predict(LogRegModel, newdata=train, type="response")
table(train$user_rating, logpred > 0.5)
# Test Set Prediction
predLogTest <- predict(LogRegModel, newdata=test_data, type="response")
table(test_data$user_rating, predLogTest > 0.5)
#Figure out baseline
#ROC
# ROC Curve
roc_pred <- prediction(predLogTest, test_data$user_rating)
logofperformance <- performance(roc_pred, "tpr", "fpr")
plot(logofperformance, colorize = TRUE)
abline(0, 1)
as.numeric(performance(roc_pred, "auc")@y.values)
#LDA
LdaMod <- lda(user_rating ~ price + rating_count_tot + prime_genre + size_bytes + cont_rating, data = train)
summary(LdaMod)
TestLDApred <- predict(LdaMod, newdata= test_data)
prob_TestLDApred <- TestLDApred$posterior[,2]
roc_lda_pred <- prediction(prob_TestLDApred, test_data$user_rating)
performance_of_lda <- performance(roc_lda_pred, "tpr", "fpr")
plot(performance_of_lda, colorize = TRUE)
abline(0, 1)
as.numeric(performance(roc_lda_pred, "auc")@y.values)
plot(logofperformance, col="violetred3")
plot(performance_of_lda, col="steelblue4", add=TRUE)
abline(0,1)
knitr::opts_chunk$set(echo = TRUE)
#use cart model and random forest
tableAccuracy <- function(test, pred) {
t = table(test, pred)
a = sum(diag(t))/length(test)
return(a)
}
library(caTools) # splits
library(rpart) # CART
library(rpart.plot) # CART plotting
library(caret) # cross validation
train$user_rating
str(train)
train$user_rating <- factor(train$user_rating, levels = c(0, 1), ordered = TRUE)
set.seed(3100)
train.cart = train(user_rating ~ price + rating_count_tot + prime_genre + size_bytes + cont_rating,
data = train,
method = "rpart",
tuneGrid = data.frame(cp = seq(0,0.4,0.002)),
trControl = trainControl(method = "cv", number = 10),
metric = "Accuracy")
train.cart
train.cart$results
ggplot(train.cart$results, aes(x = cp, y = Accuracy)) + geom_point(size = 2) + geom_line() +
ylab("CV Accuracy") + theme_bw() +
theme(axis.title=element_text(size=18), axis.text=element_text(size=18))
mod.cart = train.cart$finalModel
prp(mod.cart)
test_data.mm = as.data.frame((model.matrix(user_rating~.+0,data= test_data)))
predict.cart = predict(mod.cart, newdata = test_data.mm, type = "class")
table(test_data$user_rating, predict.cart)
tableAccuracy(test_data$user_rating, predict.cart)
